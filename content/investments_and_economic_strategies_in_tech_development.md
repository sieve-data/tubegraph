---
title: Investments and Economic Strategies in Tech Development
videoId: pE3KKUKXcTM
---

From: [[dwarkesh | The Dwarkesh Podcast]]

The development of advanced technology, particularly in [[artificial_intelligence_vs_human_intelligence | artificial intelligence (AI)]] and semiconductors, is characterized by massive capital investments, complex global supply chains, and evolving national and corporate strategies. This article outlines key economic and investment trends discussed by Dylan Patel of SemiAnalysis and Jon Y. of Asianometry.

## National Strategies and Compute Centralization

Nations are adopting distinct strategies to secure and advance their technological capabilities, especially concerning AI compute resources.

### China's Approach

China possesses significant advantages in rapidly scaling physical infrastructure but faces challenges in accessing cutting-edge chip technology due to international sanctions.

*   **Infrastructure Advantages:** China can build vast data center infrastructure quickly, with Dylan Patel noting their ability to add power capacity equivalent to "half of Europe every year" <a class="yt-timestamp" data-t="00:14:23">[00:14:23]</a>. Examples include the power density around the Three Gorges Dam, which once supported an estimated 10 gigawatts of Bitcoin mining <a class="yt-timestamp" data-t="00:14:40">[00:14:40]</a>. Patel suggests China could build a gigawatt-scale AI data center in six months and potentially hide such facilities by repurposing existing industrial sites, like aluminum mills <a class="yt-timestamp" data-t="00:15:04">[00:15:04]</a>, <a class="yt-timestamp" data-t="00:19:08">[00:19:08]</a>.
*   **Potential for Centralization:** If "scale-pilled," Xi Jinping could centralize compute resources, directing all incoming GPUs to a single massive data center <a class="yt-timestamp" data-t="00:12:55">[00:12:55]</a>, <a class="yt-timestamp" data-t="00:14:02">[00:14:02]</a>. This could allow China to train larger models than any single Western company <a class="yt-timestamp" data-t="00:17:33">[00:17:33]</a>. However, such centralization risks creating a single point of failure or stifling innovation by putting "an idiot bureaucrat at the top" <a class="yt-timestamp" data-t="00:16:54">[00:16:54]</a>.
*   **Current GPU and Domestic Chip Landscape:** China is estimated to receive over a million NVIDIA H20s and other Hopper GPUs annually, even post-sanctions <a class="yt-timestamp" data-t="00:13:01">[00:13:01]</a>. Their domestic chip production is less than a million chips per year <a class="yt-timestamp" data-t="00:13:12">[00:13:12]</a>. Despite this, the current AI efforts in China remain quite decentralized, with companies like Alibaba, Baidu, and emerging players like DeepSeek operating somewhat independently <a class="yt-timestamp" data-t="00:12:38">[00:12:38]</a>.
*   **Achieving Large-Scale Models:** Patel believes China could train a 1e27 FLOP model by 2026 using only foreign chips if they centralize <a class="yt-timestamp" data-t="00:26:46">[00:26:46]</a>, <a class="yt-timestamp" data-t="00:26:57">[00:26:57]</a>. With domestic chips like the 600,000 Ascend 910Bs, they could potentially build even larger models <a class="yt-timestamp" data-t="00:27:40">[00:27:40]</a>, possibly reaching 1e30 FLOPs before the US due to their data center deployment advantages <a class="yt-timestamp" data-t="00:28:05">[00:28:05]</a>.

### United States and Western Allies

The US and its allies feature a more decentralized ecosystem of AI development but face hurdles in infrastructure build-out.

*   **Decentralized Lab Ecosystem:** The US has numerous AI labs, including OpenAI, xAI, Anthropic, Microsoft, Meta, and various startups, fostering a decentralized innovation environment <a class="yt-timestamp" data-t="00:12:16">[00:12:16]</a>.
*   **Infrastructure Challenges:** Unlike China, the US faces significant challenges in building large data centers, substations, and transformers quickly in dense areas <a class="yt-timestamp" data-t="00:14:15">[00:14:15]</a>. Patel notes the US "adds so little power each year" in comparison <a class="yt-timestamp" data-t="00:20:09">[00:20:09]</a>.
*   **Export Controls and Their Efficacy:** US export controls aim to restrict China from acquiring superior AI, chips, and domestic chip manufacturing capabilities <a class="yt-timestamp" data-t="00:22:02">[00:22:02]</a>. Patel views these controls as somewhat ineffective, arguing that China can currently build better chips domestically (e.g., with equipment from ASML and Applied Materials) than those NVIDIA or AMD are permitted to sell to China <a class="yt-timestamp" data-t="00:22:42">[00:22:42]</a>, <a class="yt-timestamp" data-t="00:21:18">[00:21:18]</a>. Jon Y. adds that stopping the Chinese semiconductor industry's progress is "basically impossible" <a class="yt-timestamp" data-t="00:25:34">[00:25:34]</a> as the sanctions have only strengthened China's resolve <a class="yt-timestamp" data-t="00:25:51">[00:25:51]</a>.

## Global Investment Landscape for AI Infrastructure

Massive investments are flowing into AI infrastructure globally, driven by major tech companies, specialized labs, and sovereign wealth.

### Key Players and Investment Vehicles

*   **Hyperscalers:** Companies like Microsoft and Google are making substantial investments. Microsoft, for instance, is involved in building or securing capacity for hundreds of thousands of GPUs for OpenAI <a class="yt-timestamp" data-t="01:25:24">[01:25:24]</a>.
*   **Specialized AI Labs:** OpenAI is projected to need to raise $50-100 billion to fund its compute needs <a class="yt-timestamp" data-t="01:28:31">[01:28:31]</a>. xAI, led by Elon Musk, is undertaking ambitious projects like the Memphis data center, costing $4-5 billion for 100,000 GPUs <a class="yt-timestamp" data-t="01:15:41">[01:15:41]</a>.
*   **Sovereign Wealth and International Investment:**
    *   **Malaysia:** ByteDance is a major driver behind over a gigawatt of data center capacity planned for next year <a class="yt-timestamp" data-t="01:21:40">[01:21:40]</a>. Malaysia has over $10 billion in AI data center build-outs planned <a class="yt-timestamp" data-t="01:23:39">[01:23:39]</a>.
    *   **Middle East:** G42 (UAE) is developing a 100,000 GB200 cluster, administered by Microsoft for security reasons <a class="yt-timestamp" data-t="01:22:53">[01:22:53]</a>. Omniva in Kuwait is reportedly spending over $5 billion on data centers <a class="yt-timestamp" data-t="01:23:27">[01:23:27]</a>.
    *   **Ethiopia:** The Grand Ethiopian Renaissance Dam offers significant power potential (over a gigawatt), though security and IP risks make it a challenging location for major AI labs <a class="yt-timestamp" data-t="01:21:45">[01:21:45]</a>, <a class="yt-timestamp" data-t="01:22:23">[01:22:23]</a>.

### Data Center Development Strategies

Innovative approaches are being used to rapidly deploy AI compute.
*   **Repurposing Existing Infrastructure:** Converting crypto mining facilities (e.g., Core Scientific sites for OpenAI/CoreWeave) is a common strategy <a class="yt-timestamp" data-t="01:16:25">[01:16:25]</a>. xAI is using an old factory in Memphis <a class="yt-timestamp" data-t="01:15:19">[01:15:19]</a>.
*   **Innovative Power Solutions:** xAI's Memphis project involves mobile gas generators, Tesla battery packs, and tapping existing natural gas lines <a class="yt-timestamp" data-t="01:15:19">[01:15:19]</a>. Some sites, like the Core Scientific conversion, have on-site natural gas plants <a class="yt-timestamp" data-t="01:16:31">[01:16:31]</a>.
*   **ESG Considerations and Net-Zero Commitments:** Large tech companies face ESG (Environmental, Social, and Governance) pressures, which can limit their ability to use "crazy shit" power solutions like Elon Musk <a class="yt-timestamp" data-t="01:17:14">[01:17:14]</a>. Patel expects these companies might eventually drop their net-zero commitments as scaling intensifies <a class="yt-timestamp" data-t="01:17:21">[01:17:21]</a>.
*   **Power Usage Effectiveness (PUE):** Hyperscalers aim for PUEs around 1.1 (90% power to chips), while converted sites like Core Scientific's might have PUEs of 1.5-1.6 <a class="yt-timestamp" data-t="01:18:03">[01:18:03]</a>.

### The Economics of GPU Deployment

*   **Cost of Ownership Breakdown:** For an H100, power constitutes less than 15% (often sub-10%) of the total cost of ownership. The servers (GPUs) themselves account for 75-80% <a class="yt-timestamp" data-t="01:19:38">[01:19:38]</a>. This makes the marginal cost of power less critical than the ability to secure power and maximize GPU utilization (i.e., not turning them off for part of the day) <a class="yt-timestamp" data-t="01:20:01">[01:20:01]</a>, <a class="yt-timestamp" data-t="01:20:33">[01:20:33]</a>.
*   **Rental Market Dynamics:** The GPU rental market has become more of a buyer's market, with H100 prices for short/mid-term deals dropping from $3-4/hour to around $2.15/hour or less <a class="yt-timestamp" data-t="01:13:16">[01:13:16]</a>. The natural cost for a data center deploying H100s is around $1.70/hour (including debt/capital costs) <a class="yt-timestamp" data-t="01:13:39">[01:13:39]</a>.
*   **Multi-Site Training:** Microsoft and OpenAI appear to be investing heavily in connecting multiple data centers via high-speed fiber (deals with Lumen, Zayo) to enable training across distributed sites, potentially aggregating over a gigawatt of power across five regions <a class="yt-timestamp" data-t="01:24:13">[01:24:13]</a>, <a class="yt-timestamp" data-t="01:24:36">[01:24:36]</a>.

## Funding the Future: Investment Rationale and Market Dynamics

The enormous investments in AI are driven by a unique set of economic and psychological factors.

### The "Pascal's Wager" in AI Investment

Tech leaders like Satya Nadella (Microsoft), Sundar Pichai (Google), and Mark Zuckerberg (Meta) operate under a "Pascal's Wager" mindset: the risk of under-investing in AI and being left behind is perceived as far greater than the risk of over-investing [[investment_and_risk_irrationality_and_market_behavior | (Pascalâ€™s Wager)]] <a class="yt-timestamp" data-t="01:41:49">[01:41:49]</a>, <a class="yt-timestamp" data-t="01:42:23">[01:42:23]</a>. This sentiment is shared by major capital holders, including sovereign wealth funds in the UAE and Saudi Arabia <a class="yt-timestamp" data-t="01:42:30">[01:42:30]</a>.

### Revenue Generation vs. Capital Expenditure

There's a significant lag between massive capital expenditure on compute and the realization of revenue from AI models.
*   GPT-4, costing around $500 million to train, has generated billions in recurring revenue <a class="yt-timestamp" data-t="01:42:42">[01:42:42]</a>.
*   The next generation of models may cost $10-13 billion (OpenAI's effective spend) <a class="yt-timestamp" data-t="01:42:53">[01:42:53]</a>, requiring fundraising rounds of $50-100 billion <a class="yt-timestamp" data-t="01:43:18">[01:43:18]</a>.
*   Revenue from these models will take time to materialize, but investment decisions are made based on the *demonstrated potential* of new models <a class="yt-timestamp" data-t="01:43:32">[01:43:32]</a>. Patel argues that revenue in 2025-2026 is not needed to support investments made in those years, but rather to justify the capital spent on models developed in 2023-2024 <a class="yt-timestamp" data-t="01:44:15">[01:44:15]</a>.
*   The cost of intelligence is rapidly decreasing (e.g., GPT-4 API cost dropped from ~$120 to ~$10 per million tokens), which is expected to drive adoption <a class="yt-timestamp" data-t="01:14:24">[01:14:24]</a>, <a class="yt-timestamp" data-t="01:14:41">[01:14:41]</a>.

### Market Bubbles and Historical Parallels

The current AI investment boom is drawing comparisons to past tech bubbles.
*   The current private capital flowing into AI is around $55-60 billion per year, compared to ~$150 billion per year during the dot-com bubble <a class="yt-timestamp" data-t="01:48:04">[01:48:04]</a>. Patel suggests the AI "bubble" could be larger and is currently less debt-financed than the dot-com era <a class="yt-timestamp" data-t="01:48:26">[01:48:26]</a>.
*   Like the dot-com bubble which laid essential internet infrastructure despite many company failures <a class="yt-timestamp" data-t="01:48:44">[01:48:44]</a>, [[open_source_ai_models_and_their_implications | the current AI investment wave]] could build the foundation for future transformative technologies, even if some ventures don't succeed.
*   Keynes's observation that "the market can remain irrational longer than you can remain solvent" is relevant to the current investment climate <a class="yt-timestamp" data-t="01:50:19">[01:50:19]</a>, <a class="yt-timestamp" data-t="01:50:27">[01:50:27]</a>.

### The Role of Next-Generation Models (e.g., GPT-5)

The continued flow of investment is heavily contingent on upcoming AI models demonstrating significant capability improvements <a class="yt-timestamp" data-t="01:45:24">[01:45:24]</a>. A strong showing from models like GPT-5 is seen as crucial for convincing investors to commit further capital <a class="yt-timestamp" data-t="01:37:56">[01:37:56]</a>.

## Bottlenecks and Resource Allocation

The rapid scaling of AI compute faces a series of shifting bottlenecks.

### Shifting Constraints in the Supply Chain

*   In 2023, CoWoS (Chip on Wafer on Substrate) packaging was a key bottleneck <a class="yt-timestamp" data-t="01:35:06">[01:35:06]</a>.
*   Current and near-future bottlenecks include HBM (High Bandwidth Memory), CoWoS-L (a type of advanced packaging), data center construction, electrical transformers and substations, power generation, and specialized cooling systems <a class="yt-timestamp" data-t="01:35:11">[01:35:11]</a>.
*   Fabrication capacity (fabs) is expected to become a more significant constraint in the 2026-2027 timeframe <a class="yt-timestamp" data-t="01:35:27">[01:35:27]</a>.

### TSMC's Role and Future Capacity for AI

TSMC's production capacity is critical for meeting AI chip demand.
*   The economic viability of future process nodes like N2 (2-nanometer) was questionable based on mobile demand alone (Apple, TSMC's largest customer, was not driving enough demand to fully utilize planned advanced capacity) <a class="yt-timestamp" data-t="00:42:18">[00:42:18]</a>, <a class="yt-timestamp" data-t="01:33:06">[01:33:06]</a>.
*   AI has become the primary driver for these advanced nodes. By 2028, Patel envisions 60-80% of TSMC's 2nm, A16, and A14 node capacity could be dedicated to AI chips <a class="yt-timestamp" data-t="01:32:40">[01:32:40]</a>.
*   TSMC's existing plans for 2nm are aggressive and seem sufficient to support a 1e30 FLOP compute target by 2028-2029, provided demand from AI leaders like NVIDIA and Google continues to grow robustly <a class="yt-timestamp" data-t="01:32:53">[01:32:53]</a>, <a class="yt-timestamp" data-t="01:33:53">[01:33:53]</a>.

### Industrial Revitalization

The immense demand from the AI sector has the potential to revitalize ancillary industries, such as power generation equipment (transformers, substations). These industries, which saw flat or declining demand for years, are now incentivized to innovate and expand production significantly <a class="yt-timestamp" data-t="01:36:20">[01:36:20]</a>, <a class="yt-timestamp" data-t="01:37:11">[01:37:11]</a>.

## Entrepreneurial Opportunities in the Tech Stack

Despite the dominance of large players, opportunities exist for innovation and new ventures.

### Focus on Memory Innovation

Jon Y. highlights memory as a critical area for entrepreneurial focus <a class="yt-timestamp" data-t="02:07:20">[02:07:20]</a>.
*   DRAM technology scaling effectively stalled around 2012, with only incremental gains since then, while logic continued to follow Moore's Law to a greater extent <a class="yt-timestamp" data-t="02:08:06">[02:08:06]</a>.
*   Breakthroughs in memory technology or integration with accelerators could be world-changing <a class="yt-timestamp" data-t="02:07:46">[02:07:46]</a>.
*   However, entrepreneurship in memory is challenging due to the immense scale required for manufacturing and an industry structure that doesn't easily accommodate custom memory devices <a class="yt-timestamp" data-t="02:08:39">[02:08:39]</a>.

### General Opportunities Across Layers

Dylan Patel emphasizes that opportunities abound across the entire technology stack <a class="yt-timestamp" data-t="02:09:04">[02:09:04]</a>.
*   He advises entrepreneurs to find an area that genuinely engages them, as passion fuels harder work and innovation [[the_evolution_and_future_of_the_tech_industry | in the tech industry]] <a class="yt-timestamp" data-t="02:09:27">[02:09:27]</a>.
*   Utilizing AI to improve efficiency within any layer of the supply chain can lead to success <a class="yt-timestamp" data-t="02:09:52">[02:09:52]</a>.
*   Many layers of the tech stack are not yet at their "Pareto optimal" state, leaving vast room for innovation and efficiency gains <a class="yt-timestamp" data-t="02:10:23">[02:10:23]</a>.

## Conclusion

The development of AI and semiconductor technology is fueled by unprecedented levels of investment and strategic maneuvering by nations and corporations. While facing significant infrastructure and supply chain challenges, the prevailing economic sentiment, driven by a "Pascal's Wager" and the promise of transformative AI capabilities, continues to propel rapid scaling. This dynamic environment presents both immense risks and profound opportunities for innovation across the global tech landscape.