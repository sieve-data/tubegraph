---
title: Intelligence explosion and its implications
videoId: WLBsUarvWTw
---

From: [[dwarkesh | The Dwarkesh Podcast]]

The concept of an "intelligence explosion," where AI rapidly self-improves leading to superintelligence, is a prominent idea in discussions about the future of artificial intelligence. However, Tamay Besiroglu and Ege Erdil, formerly of Epoch AI and now launching Mechanize, offer a nuanced perspective, suggesting the term might be misleading and that the focus should be on a broader transformation. <a class="yt-timestamp" data-t="00:00:34">[00:00:34]</a>

## Critiquing the "Intelligence Explosion" Concept

Tamay Besiroglu argues that framing the upcoming AI-driven transformation as an "intelligence explosion" is not a very useful concept. He likens it to calling the Industrial Revolution a "horsepower explosion." <a class="yt-timestamp" data-t="00:00:56">[00:00:56]</a> While the Industrial Revolution did see a drastic acceleration in raw physical power, many other complementary changes were equally, if not more, important in explaining the acceleration of growth and technological change. <a class="yt-timestamp" data-t="00:01:04">[00:01:04]</a> These included innovations in agriculture, transportation, law and finance, and urbanization. <a class="yt-timestamp" data-t="00:01:28">[00:01:28]</a> Similarly, while AI development will produce very smart AI systems, this will be just one part among many moving parts explaining the expected transition. <a class="yt-timestamp" data-t="00:02:03">[00:02:03]</a>

## Timelines for Advanced AI

Besiroglu and Erdil generally project longer timelines for achieving Artificial General Intelligence (AGI) or full automation compared to many in the AI field.
*   Tamay Besiroglu estimates a "drop-in remote worker replacement" (an AI capable of doing literally everything that can be done remotely) could occur around **2045**. <a class="yt-timestamp" data-t="00:02:37">[00:02:37]</a>, <a class="yt-timestamp" data-t="00:02:55">[00:02:55]</a>
*   Ege Erdil is slightly more bullish but generally aligns with Besiroglu, suggesting perhaps shading predictions by five years or 20%. <a class="yt-timestamp" data-t="00:02:45">[00:02:45]</a>, <a class="yt-timestamp" data-t="00:02:57">[00:02:57]</a>

Their reasoning for these longer timelines, despite rapid recent progress (e.g., from ChatGPT to models with advanced reasoning and coding), includes:
*   **Critique of simple extrapolation:** The intuition that progress has been very fast leading to extrapolation for AGI by 2027 or 2030 is flawed. Currently, the fraction of the economy automated by AI is very small; extrapolating this trend would suggest centuries. <a class="yt-timestamp" data-t="00:03:36">[00:03:36]</a>
*   **Number of core capabilities:** They consider how many core capabilities AI systems need to achieve broad economic impact. Over the past 10-15 years, with 9-10 orders of magnitude of compute scaling, only a few "big unlocks" (like sophisticated gameplay, language capabilities, abstract reasoning/coding) have occurred, roughly one every three years or every three orders of magnitude of compute. <a class="yt-timestamp" data-t="00:04:18">[00:04:18]</a>, <a class="yt-timestamp" data-t="00:05:30">[00:05:30]</a>
*   **Remaining capabilities:** Many more competencies might be needed, such as coherence over long horizons, agency and autonomy, and full multimodal understanding. <a class="yt-timestamp" data-t="00:05:46">[00:05:46]</a>, <a class="yt-timestamp" data-t="00:06:01">[00:06:01]</a> 
*   **Compute scaling limitations:** It's becoming harder to scale up compute. Analysis suggests maybe only three or four orders of magnitude of scaling are left before a non-trivial fraction of world output would be spent on data centers, energy, and fabs. <a class="yt-timestamp" data-t="00:06:46">[00:06:46]</a>, <a class="yt-timestamp" data-t="00:07:00">[00:07:00]</a> (Currently, AI chip production is a small fraction, e.g., 5% of TSMC's leading-edge capacity <a class="yt-timestamp" data-t="00:07:18">[00:07:18]</a>, <a class="yt-timestamp" data-t="00:07:28">[00:07:28]</a>).
*   **Complexity of real-world jobs:** Many jobs are more complex than they appear. Automating a single task (like booking a flight, which Ege expects AI to do by end of 2024 <a class="yt-timestamp" data-t="00:08:13">[00:08:13]</a>, <a class="yt-timestamp" data-t="00:08:18">[00:08:18]</a>) doesn't automate the entire job, as that task is often a small fraction of what a person actually does. <a class="yt-timestamp" data-t="00:08:35">[00:08:35]</a>, <a class="yt-timestamp" data-t="00:09:11">[00:09:11]</a>

## The "Unhobblings" Debate and Current AI Capabilities

A contrasting view, articulated by Leopold Aschenbrenner, is that current models are like "baby AGIs" that are "hobbled" by artificial constraints (e.g., text-only training, limited context windows, lack of inference-time meditation). [[large_language_models_and_transfer_learning]] Removing these "unhobblings" might be easier than developing entirely new capabilities. <a class="yt-timestamp" data-t="00:10:06">[00:10:06]</a>

*   **Erdil's Counter-argument:** One could have made similar arguments about AlphaZero five years ago, but simply "unhobbling" it by training on text wouldn't have worked. New capabilities often require rethinking model training. <a class="yt-timestamp" data-t="00:10:21">[00:10:21]</a>
*   **Apparent Ease of Recent Unlocks:** While ChatGPT (chatbot capability via 1% additional compute <a class="yt-timestamp" data-t="00:10:56">[00:10:56]</a>) and reasoning capabilities (small fraction of compute on RL <a class="yt-timestamp" data-t="00:11:12">[00:11:12]</a>) seem like easy "unhobblings" now, achieving them required a massive prior build-up of technology, data, and compute scaling that would have seemed insurmountable years ago (e.g., reasoning in 2015 <a class="yt-timestamp" data-t="00:11:43">[00:11:43]</a>).
*   **Future "Easy" Unlocks:** Agency might appear similarly "easy" in hindsight after years of complementary innovations. <a class="yt-timestamp" data-t="00:12:55">[00:12:55]</a>
*   **Are Language Models the Key?** The question remains whether current language models are the "big missing piece." The AlphaGo/AlphaZero analogy suggests impressive specific capabilities don't always generalize easily (e.g., to math <a class="yt-timestamp" data-t="00:14:34">[00:14:34]</a>). It's possible current models will struggle similarly when applied to achieve broad agency. <a class="yt-timestamp" data-t="00:14:53">[00:14:53]</a> [[alphazero_and_efficient_search_techniques]]
*   **Evidence for Faster Progress:** The METR eval showing AI task length (for tasks taking humans minutes to hours) doubling every seven months suggests rapid progress towards long-term coherency. <a class="yt-timestamp" data-t="00:15:49">[00:15:49]</a>, <a class="yt-timestamp" data-t="00:16:11">[00:16:11]</a> This, and the observation that reasoning seems simpler than expected (e.g., Chain of Thought boosts <a class="yt-timestamp" data-t="00:16:55">[00:16:55]</a>), fuels arguments for shorter timelines.
*   **Critique of "Claude Plays Pokemon":** While Claude wasn't explicitly RL-trained on Pokemon Red, it has vast knowledge about it from internet data. Yet, it still gets stuck (e.g., in Mount Moon for 48 hours <a class="yt-timestamp" data-t="00:19:28">[00:19:28]</a>), highlighting a gap between explicit knowledge and effective action. <a class="yt-timestamp" data-t="00:19:00">[00:19:00]</a> [[reinforcement_learning_from_human_feedback_rlhf]]

Besiroglu would be updated by AI demonstrating long-context, multimodal capabilities integrated with reasoning and agency, especially in novel, complex environments like an un-documented game from Steam released after its training cutoff. <a class="yt-timestamp" data-t="00:20:40">[00:20:40]</a> Significant revenue (e.g., $500 billion for OpenAI, not just $100 billion <a class="yt-timestamp" data-t="00:21:45">[00:21:45]</a>, <a class="yt-timestamp" data-t="00:21:56">[00:21:56]</a>) would also be an update, although high revenue alone isn't transformative (e.g., oil market <a class="yt-timestamp" data-t="00:22:48">[00:22:48]</a>). [[impact_of_ai_on_software_development_and_productivity]]

## Automating R&D: The Core of an Intelligence Explosion?

A central tenet of the intelligence explosion theory is that AI will automate AI R&D, leading to a rapid, recursive self-improvement cycle. <a class="yt-timestamp" data-t="00:24:16">[00:24:16]</a> [[recursive_selfimprovement_and_ai_capabilities]] Proponents argue current models are already strong in coding and reasoning, key skills for AI R&D. [[impact_of_ai_on_society|Impact of AI on future technology and society]]

Besiroglu and Erdil are skeptical:
*   **Current AI R&D Capabilities:** While AIs impress in specific coding tasks (e.g., competitive programming <a class="yt-timestamp" data-t="00:25:09">[00:25:09]</a>), they lack the broader skills needed for actual research, which involves working with large, vague codebases and problems unlike the compact tasks in evals like METR. <a class="yt-timestamp" data-t="00:25:44">[00:25:44]</a>, <a class="yt-timestamp" data-t="00:25:59">[00:25:59]</a>
*   **True Nature of Research:** Automating research requires more than current models display, including the ability to introduce novel conceptual schemes (unlike current math models, which are good at solving problems but not creating new concepts <a class="yt-timestamp" data-t="00:28:25">[00:28:25]</a>, <a class="yt-timestamp" data-t="00:30:34">[00:30:34]</a>). Current reasoning models leverage vast knowledge but lack creativity; they haven't produced even minorly interesting new math concepts despite their extensive training data. <a class="yt-timestamp" data-t="00:30:43">[00:30:43]</a>, <a class="yt-timestamp" data-t="00:31:10">[00:31:10]</a> [[the_concept_and_potential_of_agi_artificial_general_intelligence_in_mathematics]]
*   **Role of Compute Scaling in R&D:** Much software progress, including in AI, has been driven by compute scaling (more GPUs, larger experiments), not just cognitive effort. <a class="yt-timestamp" data-t="00:27:01">[00:27:01]</a> Trying to envision future software innovations without accounting for future compute contexts is difficult. <a class="yt-timestamp" data-t="00:27:18">[00:27:18]</a> [[role_of_compute_in_ai_development]]

### Moravec's Paradox and AI Strengths

Moravec's Paradox posits that AI excels at tasks hard for humans (e.g., abstract reasoning, chess, Go, complex math) but struggles with tasks easy for humans (e.g., perception, motor skills). <a class="yt-timestamp" data-t="00:31:53">[00:31:53]</a>
*   **Evolutionary Perspective:** The tasks AI masters quickly are often recent in evolutionary time (e.g., advanced language, chess). Evolution had less time to optimize humans for these, and they often conferred smaller fitness gains initially. <a class="yt-timestamp" data-t="00:32:59">[00:32:59]</a>
*   **Correlation vs. Causation:** In humans, proficiency in these "hard" tasks often correlates with general competence. This correlation is weaker in AI systems. For example, the best competitive programming AIs aren't necessarily the best coding assistants. <a class="yt-timestamp" data-t="00:33:41">[00:33:41]</a>, <a class="yt-timestamp" data-t="00:34:08">[00:34:08]</a>
*   **Implication:** Rapid AI progress on tasks humans find impressive shouldn't be over-extrapolated to general competence across all economically valuable human tasks. <a class="yt-timestamp" data-t="00:34:40">[00:34:40]</a> [[artificial_intelligence_vs_human_intelligence]]

## The "Software-Only Singularity" Debate

The "software-only singularity" argument suggests that AIs improving AI software will lead to:
1.  More efficient AI copies, increasing the population of AI researchers. <a class="yt-timestamp" data-t="00:46:31">[00:46:31]</a>
2.  Cheaper experiments, as more efficient models reduce the cost of large-scale training runs. <a class="yt-timestamp" data-t="00:47:50">[00:47:50]</a> [[diffusion_of_new_technologies]]
This creates a positive feedback loop leading to rapid capability gains. <a class="yt-timestamp" data-t="00:48:14">[00:48:14]</a>

Besiroglu and Erdil's counterarguments:
*   **Diminishing Returns to R&D:** Economic studies show that while past discoveries aid current research, there are also diminishing returns as low-hanging fruit is picked. Returns to research effort in software (including AI domains like computer vision, RL, language modeling) are ambiguous regarding whether they lead to accelerating or merely exponential growth. <a class="yt-timestamp" data-t="00:48:40">[00:48:40]</a>, <a class="yt-timestamp" data-t="00:49:20">[00:49:20]</a> [[economic_growth_and_technological_development]]
*   **Complementarity of Inputs:** Experiments and hardware scaling are crucial complementary inputs. <a class="yt-timestamp" data-t="00:50:02">[00:50:02]</a> [[complementary_innovations_and_technological_progress]]
    *   Software progress often matches hardware progress (e.g., Moore's Law for traditional software, deep learning acceleration coinciding with compute acceleration). <a class="yt-timestamp" data-t="00:50:20">[00:50:20]</a>
    *   AI innovation is concentrated in GPU-rich labs. <a class="yt-timestamp" data-t="00:51:06">[00:51:06]</a> [[impact_of_ai_on_software_development_and_productivity]]
    *   Many key AI innovations are about harnessing compute more effectively (e.g., Transformer, Flash Attention, Chinchilla scaling laws). <a class="yt-timestamp" data-t="00:51:21">[00:51:21]</a>
*   **Bottlenecks:** If software efficiency improves dramatically while compute remains relatively fixed, progress will eventually be bottlenecked by compute. <a class="yt-timestamp" data-t="00:56:54">[00:56:54]</a> It's hard to get direct evidence on the strength of these complementarities as experiments with drastically imbalanced inputs are rare. <a class="yt-timestamp" data-t="00:57:26">[00:57:26]</a>, <a class="yt-timestamp" data-t="00:58:02">[00:58:02]</a>

If AGI were to arrive by 2027 (a short timeline), it would imply significant leverage from algorithmic progress, as compute wouldn't be massively larger. <a class="yt-timestamp" data-t="00:58:06">[00:58:06]</a> [[ai_developments_in_hardware_and_software_advancements]]

## Economic Transformation and the Role of AI

Besiroglu and Erdil emphasize that a profound AI-driven transformation requires more than just smarter AI; it necessitates broad economic and infrastructural upgrades. [[economic_growth_and_ai]]

### "Shenzhen in the Desert" vs. Broad Economic Integration
The idea of a self-contained, rapidly growing AI economy (a "Shenzhen in the desert" building robot factories <a class="yt-timestamp" data-t="00:07:54">[00:07:54]</a>) is more plausible than a software-only singularity. However, they argue for an even broader integration:
*   **Leveraging Existing Infrastructure:** The semiconductor supply chain is vast and complex. Replicating or rapidly scaling it independently is extremely hard. <a class="yt-timestamp" data-t="00:09:03">[00:09:03]</a>
*   **Data Dependency:** Current AI relies heavily on vast internet data accumulated over decades. Future competency gains might also efficiently leverage broad data modalities, requiring wide deployment. <a class="yt-timestamp" data-t="00:09:37">[00:09:37]</a> ChatGPT's user feedback mechanism is an example of this. <a class="yt-timestamp" data-t="00:10:32">[00:10:32]</a> [[ai_alignment_and_cooperation_challenges]]
*   **Interplay of Innovation and Capital:** Technological advancement isn't just about invention; it involves a complex interplay with capital build-out, learning by doing (e.g., solar panel efficiency <a class="yt-timestamp" data-t="00:16:32">[00:16:32]</a>), and the development of complementary inputs (e.g., better smelting for aircraft <a class="yt-timestamp" data-t="00:17:02">[00:17:02]</a>). The light bulb required not just the filament but also the electrical grid. <a class="yt-timestamp" data-t="00:18:30">[00:18:30]</a>
*   **Scale of Economy:** A larger economy supports R&D through demand, specialization, and the serendipitous discovery that comes with more activity. <a class="yt-timestamp" data-t="00:22:03">[00:22:03]</a> The development of radio telescopes and the discovery of the CMB, leading to the Big Bang theory, benefited from WWII-era radio communication advancements. <a class="yt-timestamp" data-t="00:23:03">[00:23:03]</a>

### Explosive Growth (>30% Annually)
Mechanize's thesis includes the possibility of explosive economic growth (e.g., >30% annually <a class="yt-timestamp" data-t="00:07:08">[00:07:08]</a>).
*   **Mechanism:** This differs from China's recent growth (primarily capital accumulation <a class="yt-timestamp" data-t="00:28:36">[00:28:36]</a>) because AI allows for simultaneous scaling of effective labor (AI workforce) and capital. <a class="yt-timestamp" data-t="00:29:02">[00:29:02]</a> [[economic_and_political_structures_in_historical_contexts]]
*   **Nature of Growth:** Like the Industrial Revolution, this growth would likely involve a massive expansion in product variety across all sectors, not just more of existing goods. <a class="yt-timestamp" data-t="00:30:08">[00:30:08]</a>, <a class="yt-timestamp" data-t="00:37:25">[00:37:25]</a> [[economic_growth_and_acceleration]]
*   **Consumption:** Demand would come from consuming more current goods (intensive margin, e.g., world average GDP per capita is ~$10k, while some enjoy millions <a class="yt-timestamp" data-t="00:36:58">[00:36:58]</a>) and, more importantly, a vast array of new products and services (extensive margin <a class="yt-timestamp" data-t="00:37:20">[00:37:20]</a>).
*   **Bottlenecks (Baumol, O-Ring, Regulation):** [[cost_disease_and_economic_bottlenecks]]
    *   **Baumol Cost Disease:** While a valid qualitative concern (slowest growing essential sectors become bottlenecks <a class="yt-timestamp" data-t="00:38:17">[00:38:17]</a>), quantitative analysis is needed to show it would prevent explosive growth. Human labor can reallocate to non-automated sectors, boosting output. <a class="yt-timestamp" data-t="00:40:21">[00:40:21]</a> The H100 "payback" thought experiment (H100 compute roughly equals human brain, costs ~$30k, could earn human wages, paying itself back in ~1 year <a class="yt-timestamp" data-t="00:41:32">[00:41:32]</a>) provides a quantitative anchor.
    *   **O-Ring Production:** If AIs can substitute for all "rings" in a production process, this model doesn't inherently prevent scaling. <a class="yt-timestamp" data-t="00:43:06">[00:43:06]</a>, <a class="yt-timestamp" data-t="00:43:51">[00:43:51]</a>
    *   **Regulation:** This is considered the strongest potential impediment. <a class="yt-timestamp" data-t="00:45:09">[00:45:09]</a>, <a class="yt-timestamp" data-t="00:45:24">[00:45:24]</a> While international competition and strong incentives to adopt AI exist, global coordination to restrict technology (e.g., human cloning <a class="yt-timestamp" data-t="00:45:51">[00:45:51]</a>) is possible, though less likely for AI due to its value and national security implications. <a class="yt-timestamp" data-t="00:46:03">[00:46:03]</a> Growth differentials will likely be delineated by regulatory jurisdictions. <a class="yt-timestamp" data-t="00:27:21">[00:27:21]</a> [[challenges_in_ai_governance]]
    *   **Deployment Time:** While deploying new technologies takes time as companies adapt, if AIs become true drop-in worker replacements, onboarding could be rapid (e.g., similar to human onboarding times of ~6 months <a class="yt-timestamp" data-t="00:48:41">[00:48:41]</a>). ChatGPT itself saw extremely fast adoption. <a class="yt-timestamp" data-t="00:48:27">[00:48:27]</a>

## AI Firms: A New Paradigm of Organization

A key aspect of the future AI economy will be "AI firms" â€“ organizations predominantly or fully run by AI. <a class="yt-timestamp" data-t="00:49:39">[00:49:39]</a> These firms will possess transformative collective advantages over human-run firms:
*   **High-Fidelity Replication:** The ability to perfectly copy AI workers, including their tacit knowledge and cultural imprints, overcomes issues of culture dilution, employee turnover, and loss of expertise seen in human firms. <a class="yt-timestamp" data-t="00:50:02">[00:50:02]</a> This enables a more potent form of organizational evolution. <a class="yt-timestamp" data-t="00:50:52">[00:50:52]</a>
*   **Alignment and Incentive Structures:** AI workers can be fine-tuned with desired preferences, potentially eliminating principal-agent problems. <a class="yt-timestamp" data-t="00:52:23">[00:52:23]</a>, <a class="yt-timestamp" data-t="00:52:51">[00:52:51]</a>
*   **Information Bandwidth and Cohesion:** A "hyper-Jensen" model, where a highly capable central AI (or AI system) oversees and integrates all aspects of the firm (press releases, code reviews, customer service), could maintain an unprecedented level of coherent vision. <a class="yt-timestamp" data-t="00:53:32">[00:53:32]</a>
*   **Economies of Scale in Intelligence:** More compute allows not just more AI workers, but *smarter* AI workers, as more training compute can be dedicated to improving the base models. <a class="yt-timestamp" data-t="00:54:25">[00:54:25]</a>
*   **Elimination of Redundant Learning:** AI systems can learn once (via a massive training run) and this knowledge can be deployed everywhere, unlike humans who each learn from scratch. <a class="yt-timestamp" data-t="00:54:53">[00:54:53]</a>

### Central Planning in an AI Economy
The unique capabilities of AI firms raise questions about the viability of central planning:
*   **Arguments for Increased Viability:** <a class="yt-timestamp" data-t="00:55:23">[00:55:23]</a>
    *   Greatly increased communication bandwidth. <a class="yt-timestamp" data-t="00:55:51">[00:55:51]</a>
    *   Disaggregation of sensing (data collection at periphery) and processing (centralized analysis), as seen in Tesla FSD. <a class="yt-timestamp" data-t="00:56:00">[00:56:00]</a>, <a class="yt-timestamp" data-t="00:56:43">[00:56:43]</a>
    *   Central planners (large AI models) can be vastly more capable ("bigger brains") than individual agent AIs. <a class="yt-timestamp" data-t="00:57:17">[00:57:17]</a>
    *   Reduced need for market mechanisms if AIs are perfectly aligned with the central plan. <a class="yt-timestamp" data-t="00:57:39">[00:57:39]</a>
*   **Counterarguments:** While traditional objections to central planning may weaken, new complexities arise. A vastly larger and more complex AI economy increases the information processing burden, even with more capable AI. (Analogy: Apple today could plan the economy of ancient Uruk, but not the current world economy. <a class="yt-timestamp" data-t="00:58:33">[00:58:33]</a>)
*   **Overall Assessment:** Likely not optimal, but potentially more viable than in human economies. <a class="yt-timestamp" data-t="00:55:33">[00:55:33]</a> [[decentralization_vs_central_planning_in_economics]]

## The Concept of "Superhuman Intelligence" (ASI)

While acknowledging the possibility of AI surpassing human capabilities across the board (ASI), Besiroglu and Erdil find the concept less useful for analyzing the transition than focusing on real-world economic and societal effects. <a class="yt-timestamp" data-t="00:30:32">[00:30:32]</a>, <a class="yt-timestamp" data-t="00:31:04">[00:31:04]</a>
*   AI capability profiles are "jagged," making an "average human level" hard to define. <a class="yt-timestamp" data-t="00:31:38">[00:31:38]</a>
*   Drastic acceleration can occur without ASI, and ASI could exist without acceleration (e.g., if it's too expensive/slow). <a class="yt-timestamp" data-t="00:32:09">[00:32:09]</a>
*   The human level isn't a privileged point on scaling curves. <a class="yt-timestamp" data-t="00:33:44">[00:33:44]</a>
*   Future AIs will be diverse; some capabilities will be beyond human comprehension, similar to how many current technologies are not understood by most individuals. This is seen as an acceptable trade-off for advanced technology and improved quality of life. <a class="yt-timestamp" data-t="00:35:02">[00:35:02]</a>, <a class="yt-timestamp" data-t="00:35:53">[00:35:53]</a>

## Accelerating AI: Rationale and Concerns

Mechanize aims to accelerate the broad automation of labor. <a class="yt-timestamp" data-t="02:13:03">[02:13:03]</a> [[ai_alignment_and_safety_concerns]]
*   **Rationale for Acceleration:**
    *   Enormous economic growth, wealth, and unimaginable new products (e.g., in healthcare). <a class="yt-timestamp" data-t="02:13:24">[02:13:24]</a> [[the_impact_of_ai_and_quantum_computing_on_industries_like_gaming_and_healthcare]]
    *   Improved quality of life. Initially, wages may rise due to complementarity; long-term, wealth from capital ownership is expected even if wages fall due to arbitrage with AIs. <a class="yt-timestamp" data-t="02:13:43">[02:13:43]</a>
    *   The cost of delay is immense: a one-year delay could mean tens of trillions of dollars in foregone consumption or 100-200 million preventable deaths. <a class="yt-timestamp" data-t="02:15:01">[02:15:01]</a>, <a class="yt-timestamp" data-t="02:17:53">[02:17:53]</a> [[the_potential_economic_and_social_impacts_of_agi]]
*   **Addressing Safety Concerns:**
    *   It's unclear if slowing down AI development improves safety. <a class="yt-timestamp" data-t="02:15:59">[02:15:59]</a>
    *   Alignment research itself may depend on continued scaling. Trying to solve alignment in 2016 with 2016-level compute would have yielded little progress; a similar situation might apply today if scaling is paused. <a class="yt-timestamp" data-t="02:16:15">[02:16:15]</a> [[challenges_and_important_in_ai_alignment]]
    *   Leverage over the long-term future is likely low in absolute terms, even if relatively higher now. The transformation is expected to be diffuse, not concentrated in a few labs making idiosyncratic decisions with massive founder effects. <a class="yt-timestamp" data-t="02:18:38">[02:18:38]</a>, <a class="yt-timestamp" data-t="02:19:28">[02:19:28]</a>

### Concerns about Value Lock-in and Digital Suffering
*   **Value Lock-in:** Skepticism exists about the idea that current values could be "locked in" for millennia by a single AI. This assumes a stable "one AI" with an unchangeable utility function, which seems unlike past historical dynamics. Digital information itself is not inherently permanent (link rot), and technological change often drives cultural change. <a class="yt-timestamp" data-t="01:48:31">[01:48:31]</a>, <a class="yt-timestamp" data-t="01:49:36">[01:49:36]</a> Even if technological maturity is reached, predicting or influencing post-lock-in values from today's vantage point is exceedingly difficult, perhaps more so than for someone in the 1500s trying to influence today. <a class="yt-timestamp" data-t="01:51:35">[01:51:35]</a>, <a class="yt-timestamp" data-t="01:52:06">[01:52:06]</a> [[impact_of_ai_on_society|exploration of the future of society and economy with AI]]
*   **Digital Suffering:** The concern about vast digital suffering (e.g., an AI equivalent of factory farming <a class="yt-timestamp" data-t="01:54:39">[01:54:39]</a>, <a class="yt-timestamp" data-t="02:01:15">[02:01:15]</a>) is taken seriously. The recommended approach is to discount the far future due to epistemic uncertainty about the impact of current actions, and focus on near-term beneficial actions:
    *   Aligning present AI systems to value well-being and dislike suffering. <a class="yt-timestamp" data-t="02:02:39">[02:02:39]</a>
    *   Building institutional capacity to intervene if such negative outcomes start to materialize. <a class="yt-timestamp" data-t="02:02:52">[02:02:52]</a>
    *   Historical changes like the abolition of slavery were driven by deep economic and value shifts during the Industrial Revolution, not solely by contingent activist efforts. <a class="yt-timestamp" data-t="01:55:00">[01:55:00]</a>, <a class="yt-timestamp" data-t="01:58:22">[01:58:22]</a> Future values will likely be shaped more by the new technological and economic environment than by specific actions today. <a class="yt-timestamp" data-t="01:57:39">[01:57:39]</a> [[impact_and_future_of_ai_in_economic_systems]]

## Navigating an Uncertain Future

The path to an AI-transformed world is highly uncertain. <a class="yt-timestamp" data-t="02:04:34">[02:04:34]</a>
*   **Embracing Uncertainty:** Given the difficulty in prediction, a stance of epistemic humility is warranted. Classical liberalism, decentralization of knowledge and decision-making, and freedom are seen as robust societal approaches. <a class="yt-timestamp" data-t="02:05:25">[02:05:25]</a>
*   **Flexibility over Rigid Planning:** Maintaining flexibility and the ability to adapt to new information is more crucial than creating detailed, fixed plans today, which are likely to become obsolete. <a class="yt-timestamp" data-t="02:06:51">[02:06:51]</a> (Analogy: Pre-WWII plans for aerial bombardment casualties were orders of magnitude wrong <a class="yt-timestamp" data-t="02:08:01">[02:08:01]</a>, <a class="yt-timestamp" data-t="02:09:06">[02:09:06]</a>).
*   **The Power and Limits of Reason:** A core underlying disagreement in AI futures discussions is the power of abstract reasoning alone versus the necessity of empirical grounding and real-world data/experiments to understand and shape outcomes. <a class="yt-timestamp" data-t="02:11:21">[02:11:21]</a>, <a class="yt-timestamp" data-t="02:12:46">[02:12:46]</a> [[forecasting_ai_progress_and_the_intelligence_explosion]]

For individuals interested in contributing to understanding this future, Besiroglu and Erdil advise:
*   Following curiosity and intrinsic interest rather than a forced multidisciplinary strategy. <a class="yt-timestamp" data-t="03:00:07">[03:00:07]</a>
*   Aggressively reaching out to and collaborating with insightful people. <a class="yt-timestamp" data-t="03:01:08">[03:01:08]</a>, <a class="yt-timestamp" data-t="03:01:56">[03:01:56]</a>
*   Prioritizing reading key, impactful literature and empirical work identified by trusted thinkers in the field. <a class="yt-timestamp" data-t="03:03:42">[03:03:42]</a>, <a class="yt-timestamp" data-t="03:05:00">[03:05:00]</a>
*   Being part of a community to stay informed about important problems and techniques, as reasoning in isolation is less effective. <a class="yt-timestamp" data-t="03:02:32">[03:02:32]</a>, <a class="yt-timestamp" data-t="03:06:20">[03:06:20]</a> The internet and platforms like Twitter can be highly efficient for information acquisition. <a class="yt-timestamp" data-t="03:04:30">[03:04:30]</a> [[ai_trajectory_and_scaling_hypothesis]]